---
layout: post
title: "Ethical dimensions"
date: 2016-03-01
---


This chapter will address the various and numerous sociocultural implications surrounding artificial intelligence and machine learning, including ethical and political considerations. It will be mostly a big survey of these, and may be broken out into smaller chapters in the future.

# Increasing pervasiveness of machine intelligence

Nevertheless, AI systems are widespread now and already, problems which most of the ill-informed movies ignore. There are _already_ clear and present dangers, and issues we are increasingly confronting. 

Companies are rethinking their strategies, which means many complex decisions will be sorted out in the near future.

http://us8.campaign-archive1.com/?u=bdb368b9a389b010c19dbcd54&id=f2e0882b79
http://socialmediacollective.org/reading-lists/critical-algorithm-studies/
https://www.reddit.com/r/science/comments/45k2pv/science_ama_series_we_study_how_intelligent/

google ceo:
”Machine learning is a core, transformative way by which we’re rethinking everything we’re doing,” he said.
http://www.pcworld.com/article/2996620/business/google-reports-strong-profit-says-its-rethinking-everything-around-machine-learning.html

credit card fraud, 

In personal communications, we are all familiar with spam filters. But as Google and other companies begin rolling out products like Inbox, we are seeing machine intelligence take up e-mail and communications organization more generally, by offering to sort and group your e-mail according to subject analysis. This is already done, not without controversy, in the retail and commercial sectors where products and inventories are organized by algorithms. With interpersonal communications, these questions persist and hit closer to home.

Questions like:


 - When these algorithms are permitted to scan our e-mails, what else do they use the analysis for? Do they store the results, do they share them, do they sell them?
 - These algorithms affect which of our e-mails we are more likely to see than other ones. How do they make such discriminations? Knowing that setting them up in different ways may sort them differently, how do we decide one method vs another.

Like in the trolley problem, there are no obvious solutions to these, partly because they are subjective questions. So how are these decisions arrived at? We've seen that various settings and free parameters, and certainly entire architectures have enormous influence on the behavior of these algorithms. Which of these levers are exposed to the user, and which are conveniently automated? How much agency does the user have with respect to that question? 

There is a conflict of interest inherent in the last problem. Other entities have a stake in these decisions, in addition to the user. Are some topics favored against others?

Various implications of 

[ Inbox:: I'll give you Tuesday/Thursday ]

# The trolley problem and the issue of agency

There is an old __ . A more concrete example of this is the Google driverless car -- forced to make a decision who to kill, how does it decide? These are questions with no obvious answers, and even fewer explicit legal frameworks exist to answer them.  many have made much commentary about it.

# Algorithmic accountability and bias

that great disseration

# Access to data, research, and tools

Asymmetric access in public / private sphere to resources.

# Surveillance and profiling

Terror tuesdays

# Genetic surveillance

HDH has explored this since her work with stranger visions, and subsequent ones.

# Diversity in research and adjacent fields

The research sector in AI and machine learning suffers from what plagues many fields more generally, particularly the overall field of computer science.

WIML
The situation with respect to racial and socioeconomic differences is even more dramatic. Fewer than 3%(?) are POC
Even less racial and socioeconomic 


# Rights of man, rights of machine?

Descartes re: dogs, dogs do not have feelings, you may hurt them

thriving <-> abuse

[robot walking along, robot getting messed with, robot getting pushed over]

If you think these questions are overly speculative, long shots, or far off, I invite you to watch to view the robot from the Boston Dynamic group Robot. try to watch this without having feelings

As machines demonstrate more autonomy, can they act out of self-preservation? Nature shows us that self-preservation is a helpful instinct to have and thus selected for it. Will humans, in order to make machines more effective, select for self-preservational qualities? If they begin to clamor for more support, how will we react?

# Meta-ethics

These questions are relevant even to the design of this book! Certain technical features are encapsulated and hidden for the sake of accessibility. Does it encourage reductionist thinking? 


## tbd







AMI on ethics
https://www.reddit.com/r/science/comments/45k2pv/science_ama_series_we_study_how_intelligent/
 - self driving cars -- humans outlawed to drive in future?
 - what about vs planes
 - scifi writers as social theorists
   - e.g. asimov caves of steel - jobs + robots 


https://en.wikipedia.org/wiki/Trolley_problem


andrew ng "Worrying about killer robots is like worrying about overpopulation on Mars – we'll have plenty of time to figure it out." http://www.rollingstone.com/culture/features/inside-the-artificial-intelligence-revolution-a-special-report-pt-1-20160229#ixzz41aAUSmUe 


http://www.nature.com/news/machine-ethics-the-robot-s-dilemma-1.17881
http://www.nature.com/news/robotics-ethics-of-artificial-intelligence-1.17611